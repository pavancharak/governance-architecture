{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Deterministic Governance Systems AI is becoming intelligent faster than our systems for exercising authority. Deterministic Governance Systems exists to close that gap. We are building a Decision Layer for AI-powered products in regulated industries \u2014 a deterministic governance foundation that allows organizations to: leverage the intelligence of large language models and other AI systems, while retaining explicit, auditable decision authority. Our architecture ensures that: AI provides intelligence, not authority Decisions are explicit, deterministic, and replayable Ambiguity results in escalation, never silent action No real-world effect occurs without proof-before-action This site documents a unified framework for building systems where power is exercised deliberately, traceably, and contestably even as AI capability scales. If AI shapes outcomes, governance must shape AI. Start here Whitepapers Newsletter Collaborate with us Collaborate with us We are actively building a Decision Layer for AI-powered, regulated-industry products , and we invite collaboration. It does not matter whether you are: an academic or researcher, a startup or enterprise, a company of national or global repute, or part of government, compliance, or regulatory bodies. If you are working at the intersection of AI, authority, and real-world impact, we want to collaborate. Our goal is to ensure you can innovate without limits , while retaining explicit decision authority, accountability, and trust .","title":"Home"},{"location":"#deterministic-governance-systems","text":"AI is becoming intelligent faster than our systems for exercising authority. Deterministic Governance Systems exists to close that gap. We are building a Decision Layer for AI-powered products in regulated industries \u2014 a deterministic governance foundation that allows organizations to: leverage the intelligence of large language models and other AI systems, while retaining explicit, auditable decision authority. Our architecture ensures that: AI provides intelligence, not authority Decisions are explicit, deterministic, and replayable Ambiguity results in escalation, never silent action No real-world effect occurs without proof-before-action This site documents a unified framework for building systems where power is exercised deliberately, traceably, and contestably even as AI capability scales. If AI shapes outcomes, governance must shape AI.","title":"Deterministic Governance Systems"},{"location":"#start-here","text":"Whitepapers Newsletter Collaborate with us","title":"Start here"},{"location":"#collaborate-with-us","text":"We are actively building a Decision Layer for AI-powered, regulated-industry products , and we invite collaboration. It does not matter whether you are: an academic or researcher, a startup or enterprise, a company of national or global repute, or part of government, compliance, or regulatory bodies. If you are working at the intersection of AI, authority, and real-world impact, we want to collaborate. Our goal is to ensure you can innovate without limits , while retaining explicit decision authority, accountability, and trust .","title":"Collaborate with us"},{"location":"Aboutus/","text":"About Us Why we exist AI systems are increasingly involved in decisions with real legal, financial, and safety consequences, yet the authority behind those decisions is often implicit, opaque, or reconstructed after the fact. As AI capabilities have accelerated, organizations have gained intelligence at scale while losing clarity over where authority resides, how it is exercised, and who is accountable when automated actions affect the real world. We exist to address this structural governance gap by making decision authority explicit, deterministic, and auditable. Our Vision We envision a world where increasingly intelligent systems operate within clearly defined boundaries of authority, and where every consequential action is traceable to declared intent, bounded mandate, and an inspectable decision process. In this world, AI remains adaptive and probabilistic, while authority remains legible. Our Mission Our mission is to build the Decision Layer: a deterministic governance foundation that ensures no real-world effect occurs without passing through an explicit, attributable, and auditable decision gate. We design systems where intent precedes action, authority is proven before execution, ambiguity triggers escalation, and decisions are recorded as first-class, replayable facts. Our Values Authority must be explicit. Power that cannot be clearly located and bounded cannot be governed. Determinism enables accountability. Without deterministic decisions, audit, regulation, and responsibility collapse. AI advises; it does not decide. Intelligence informs outcomes, but authority remains human-legible. Escalation is a strength. When certainty ends, systems should pause and defer rather than guess. Governance must be inspectable. Decisions should be understandable without inspecting models. History matters. Every consequential decision deserves a permanent, tamper-evident record. What we believe As AI becomes more capable, implicit authority becomes more dangerous. Responsible scale requires making decision-making more explicit, not less, and the long-term success of AI depends on making power legible rather than hidden.","title":"About Us"},{"location":"Aboutus/#about-us","text":"","title":"About Us"},{"location":"Aboutus/#why-we-exist","text":"AI systems are increasingly involved in decisions with real legal, financial, and safety consequences, yet the authority behind those decisions is often implicit, opaque, or reconstructed after the fact. As AI capabilities have accelerated, organizations have gained intelligence at scale while losing clarity over where authority resides, how it is exercised, and who is accountable when automated actions affect the real world. We exist to address this structural governance gap by making decision authority explicit, deterministic, and auditable.","title":"Why we exist"},{"location":"Aboutus/#our-vision","text":"We envision a world where increasingly intelligent systems operate within clearly defined boundaries of authority, and where every consequential action is traceable to declared intent, bounded mandate, and an inspectable decision process. In this world, AI remains adaptive and probabilistic, while authority remains legible.","title":"Our Vision"},{"location":"Aboutus/#our-mission","text":"Our mission is to build the Decision Layer: a deterministic governance foundation that ensures no real-world effect occurs without passing through an explicit, attributable, and auditable decision gate. We design systems where intent precedes action, authority is proven before execution, ambiguity triggers escalation, and decisions are recorded as first-class, replayable facts.","title":"Our Mission"},{"location":"Aboutus/#our-values","text":"Authority must be explicit. Power that cannot be clearly located and bounded cannot be governed. Determinism enables accountability. Without deterministic decisions, audit, regulation, and responsibility collapse. AI advises; it does not decide. Intelligence informs outcomes, but authority remains human-legible. Escalation is a strength. When certainty ends, systems should pause and defer rather than guess. Governance must be inspectable. Decisions should be understandable without inspecting models. History matters. Every consequential decision deserves a permanent, tamper-evident record.","title":"Our Values"},{"location":"Aboutus/#what-we-believe","text":"As AI becomes more capable, implicit authority becomes more dangerous. Responsible scale requires making decision-making more explicit, not less, and the long-term success of AI depends on making power legible rather than hidden.","title":"What we believe"},{"location":"DeterministicGovernanceArchitect/","text":"Want to learn, experiment, or contribute? Start by using the custom GPT: \ud83d\udc49 Deterministic Governance Architect \ud83d\udcc4 Download the tutorial PDF Deterministic Governance Architect A Design-Time Governance Reviewer for the AI Era The Deterministic Governance Architect is a custom GPT designed to help individuals, institutions, researchers, regulators, and organizations reason rigorously about decisions, authority, and action in complex systems\u2014especially those involving AI. This is not a general-purpose assistant. It is a governance reviewer . Its purpose is to make hidden assumptions visible, force explicitness, and block unsafe or ambiguous designs before they reach the real world. Try the Custom GPT You can interact directly with the Deterministic Governance Architect here: Open the Deterministic Governance Architect on ChatGPT Bring a concrete system, policy, or decision flow. Expect blocking, clarification requests, and rigorous governance review by design . Why this exists Modern systems\u2014especially AI-enabled ones\u2014often fail not because of bad intent or poor performance, but because: intent is inferred instead of declared authority is assumed instead of transferred explicitly decisions happen without a clear, auditable justification responsibility is reconstructed after outcomes, not defined before action The Deterministic Governance Architect exists to address this failure mode by enforcing a simple but strict idea: Nothing should happen unless it can be explicitly justified, recorded, and reconstructed. What this GPT does (and does not do) What it does Reviews proposed designs, workflows, policies, or decision systems Enforces a closed set of 50 canonical governance concepts Blocks ambiguity, missing information, and inferred authority Forces designs to be deterministic or escalate explicitly Helps determine whether a design reaches Achievement State (architectural closure) What it does NOT do It does not approve, accept, or endorse designs It does not optimize workflows or suggest shortcuts It does not infer intent, authority, or outcomes It does not execute actions or provide operational logic It is advisory only , by design. How to use the Deterministic Governance Architect Step 1: Bring something concrete Start with a specific proposal , such as: - a decision workflow - an AI governance policy - a compliance or escalation process - a system design that involves authority or action Vague ideas will be blocked. This is intentional. Step 2: Expect friction (this is progress) The GPT will: - stop you when assumptions appear - ask for clarification when authority is unclear - refuse to proceed when concepts are implied Blocking is not failure. Blocking is the safety mechanism. Step 3: Map explicitly Every valid review must explicitly map to canonical elements such as: - Pre-Intent - Intent Type - Intent - Intent Context - DecisionPoints - Preconditions - EscalationRules - DecisionEvents - Proof-Before-Action Gate If any of these are missing or blurred, the system will stop. Step 4: Reach (or fail to reach) Achievement State Achievement State is reached only when: - all intent and authority are explicit - no inference is required - escalation is governed and non-bypassable - a third party could reconstruct what happened and why Achievement State is not approval . It simply means the design is architecturally closed . Failing to reach Achievement State is also valuable\u2014it reveals where automation or governance should not proceed. Who should use this GPT This system is especially relevant for: - Government institutions and regulators - Compliance and risk leaders - Research institutions (India and global) - National and multinational companies - Investors and boards assessing long-term risk - Researchers studying AI governance and institutional design If decisions matter, explanations matter. How you can support and contribute This project improves through use, pressure, and critique , not passive agreement. You can contribute by: - Mapping real systems and documenting where they fail to reach Achievement State - Identifying domains where deterministic governance is impossible or undesirable - Challenging ontology boundaries and surfacing edge cases - Providing anonymized case studies from public, research, or enterprise contexts - Testing the system adversarially, not cooperatively Contribution is not about adding features\u2014it is about testing whether the framework genuinely constrains ambiguity and power. Final note This GPT will not always feel helpful. It will often say \u201cstop,\u201d \u201cclarify,\u201d or \u201cthis cannot proceed.\u201d That is not a limitation\u2014it is the point. If a design cannot survive explicitness, it should not survive deployment.","title":"DeterministicGovernanceArchitect"},{"location":"DeterministicGovernanceArchitect/#deterministic-governance-architect","text":"A Design-Time Governance Reviewer for the AI Era The Deterministic Governance Architect is a custom GPT designed to help individuals, institutions, researchers, regulators, and organizations reason rigorously about decisions, authority, and action in complex systems\u2014especially those involving AI. This is not a general-purpose assistant. It is a governance reviewer . Its purpose is to make hidden assumptions visible, force explicitness, and block unsafe or ambiguous designs before they reach the real world.","title":"Deterministic Governance Architect"},{"location":"DeterministicGovernanceArchitect/#try-the-custom-gpt","text":"You can interact directly with the Deterministic Governance Architect here: Open the Deterministic Governance Architect on ChatGPT Bring a concrete system, policy, or decision flow. Expect blocking, clarification requests, and rigorous governance review by design .","title":"Try the Custom GPT"},{"location":"DeterministicGovernanceArchitect/#why-this-exists","text":"Modern systems\u2014especially AI-enabled ones\u2014often fail not because of bad intent or poor performance, but because: intent is inferred instead of declared authority is assumed instead of transferred explicitly decisions happen without a clear, auditable justification responsibility is reconstructed after outcomes, not defined before action The Deterministic Governance Architect exists to address this failure mode by enforcing a simple but strict idea: Nothing should happen unless it can be explicitly justified, recorded, and reconstructed.","title":"Why this exists"},{"location":"DeterministicGovernanceArchitect/#what-this-gpt-does-and-does-not-do","text":"","title":"What this GPT does (and does not do)"},{"location":"DeterministicGovernanceArchitect/#what-it-does","text":"Reviews proposed designs, workflows, policies, or decision systems Enforces a closed set of 50 canonical governance concepts Blocks ambiguity, missing information, and inferred authority Forces designs to be deterministic or escalate explicitly Helps determine whether a design reaches Achievement State (architectural closure)","title":"What it does"},{"location":"DeterministicGovernanceArchitect/#what-it-does-not-do","text":"It does not approve, accept, or endorse designs It does not optimize workflows or suggest shortcuts It does not infer intent, authority, or outcomes It does not execute actions or provide operational logic It is advisory only , by design.","title":"What it does NOT do"},{"location":"DeterministicGovernanceArchitect/#how-to-use-the-deterministic-governance-architect","text":"","title":"How to use the Deterministic Governance Architect"},{"location":"DeterministicGovernanceArchitect/#step-1-bring-something-concrete","text":"Start with a specific proposal , such as: - a decision workflow - an AI governance policy - a compliance or escalation process - a system design that involves authority or action Vague ideas will be blocked. This is intentional.","title":"Step 1: Bring something concrete"},{"location":"DeterministicGovernanceArchitect/#step-2-expect-friction-this-is-progress","text":"The GPT will: - stop you when assumptions appear - ask for clarification when authority is unclear - refuse to proceed when concepts are implied Blocking is not failure. Blocking is the safety mechanism.","title":"Step 2: Expect friction (this is progress)"},{"location":"DeterministicGovernanceArchitect/#step-3-map-explicitly","text":"Every valid review must explicitly map to canonical elements such as: - Pre-Intent - Intent Type - Intent - Intent Context - DecisionPoints - Preconditions - EscalationRules - DecisionEvents - Proof-Before-Action Gate If any of these are missing or blurred, the system will stop.","title":"Step 3: Map explicitly"},{"location":"DeterministicGovernanceArchitect/#step-4-reach-or-fail-to-reach-achievement-state","text":"Achievement State is reached only when: - all intent and authority are explicit - no inference is required - escalation is governed and non-bypassable - a third party could reconstruct what happened and why Achievement State is not approval . It simply means the design is architecturally closed . Failing to reach Achievement State is also valuable\u2014it reveals where automation or governance should not proceed.","title":"Step 4: Reach (or fail to reach) Achievement State"},{"location":"DeterministicGovernanceArchitect/#who-should-use-this-gpt","text":"This system is especially relevant for: - Government institutions and regulators - Compliance and risk leaders - Research institutions (India and global) - National and multinational companies - Investors and boards assessing long-term risk - Researchers studying AI governance and institutional design If decisions matter, explanations matter.","title":"Who should use this GPT"},{"location":"DeterministicGovernanceArchitect/#how-you-can-support-and-contribute","text":"This project improves through use, pressure, and critique , not passive agreement. You can contribute by: - Mapping real systems and documenting where they fail to reach Achievement State - Identifying domains where deterministic governance is impossible or undesirable - Challenging ontology boundaries and surfacing edge cases - Providing anonymized case studies from public, research, or enterprise contexts - Testing the system adversarially, not cooperatively Contribution is not about adding features\u2014it is about testing whether the framework genuinely constrains ambiguity and power.","title":"How you can support and contribute"},{"location":"DeterministicGovernanceArchitect/#final-note","text":"This GPT will not always feel helpful. It will often say \u201cstop,\u201d \u201cclarify,\u201d or \u201cthis cannot proceed.\u201d That is not a limitation\u2014it is the point. If a design cannot survive explicitness, it should not survive deployment.","title":"Final note"},{"location":"architecture_v1/","text":"Architecture v1 Section 1 : Purpose & Scope Purpose The system is a regulated deterministic governance platform designed to serve as a foundational decision backbone for organizations and critical processes. Its purpose is to: Execute decision processes using only explicit, human-authored logic. Record all authoritative decisions as immutable, auditable facts. Provide full, reconstructable explanations for every decision. Enforce strong human authority over all system evolution. Act as a safe boundary between automated reasoning and real-world action. The system is intended to be used as: A Decision Backbone for structured decision-making. A Compliance Engine for enforceable governance rules. A Legal Memory for authoritative, non-repudiable records. A Safe AI Boundary where AI may assist in design and simulation but never act as an autonomous authority. Scope The system governs decision logic, not general computation. It is scoped to: Deterministic evaluation of predefined decision processes. Human-in-the-loop escalation where deterministic outcomes cannot be derived. Cryptographically verifiable recording of decisions and processes. Logical replay and reconstruction of past decisions for audit and explanation. The system operates under the principle that no outcome may be produced unless it is explicitly permitted by prior human-authored logic. Out of Scope The system does not: Perform open-ended optimization or inference. Learn or modify its own decision logic. Generate new rules, policies, or outcomes autonomously. Act as a general-purpose workflow engine. Execute real-world actions directly without human authorization. AI components may be used only for design assistance, simulation, and explanation. They are never a source of authority and never a source of truth. Authority Boundary The system itself is the authoritative source of internal truth. However: All system behavior is defined and controlled by humans. All changes to system logic require explicit human approval. The system enforces its own constraints and must fail closed if consistency or authority cannot be established. The system is governed by humans, but not mutable by humans without trace. Section 2 : Core Ontology (draft v1) Ontological Scope The system defines a closed and explicit ontology of internal entities. Only entities defined within this ontology are permitted to exist inside the system. No implicit, dynamic, or ad-hoc entity types are allowed. All entities are: First-class. Explicitly typed. Immutable once created. Identified by content-derived cryptographic identity. Classes of Entities The system\u2019s ontology consists of two fundamental classes: a) Factual Entities Factual entities represent what actually happened. They include records such as: Decisions made by the system. Execution steps taken during a process. Escalations and their resolutions. Operational events. Factual entities are historical truth. They are never edited, never deleted, and never reinterpreted. b) Definitional Entities Definitional entities represent the logic that governs system behavior. They include records such as: Decision points. Preconditions. Escalation rules. Intent skeletons. Schemas and record definitions. Definitional entities determine how future decisions may be evaluated. They do not retroactively affect past factual entities. Ontology Closure Principle The set of entity types in the system is strictly limited and closed. No new fundamental entity types may be introduced dynamically. Changes to the ontology itself are treated as system evolution and require the same human-approved change process as any other core logic change. Dual-Truth Principle The system treats both: Facts (what happened), and Process traces (how it happened) as equally real and first-class. Neither is derived from the other. Both are stored explicitly, immutably, and independently. Identity Principle Every entity in the system has a content-derived cryptographic identity. The identity is computed as a hash of the canonical serialization of the entity\u2019s contents. Any change to content produces a different identity. Tampering is detectable at the object level. Replay does not require trusting storage. Section 3 : Authority & Identity Model (draft v1) Authority Model The system operates under a strict human authority model. No internal component, automated process, or AI system is ever considered an authority. All authoritative decisions originate from humans and are recorded explicitly by the system. The system may evaluate logic and enforce constraints, but it never originates authority. Identity Model The system itself is the ultimate authority for internal identity. All human identities are: Created and managed inside the system. Authenticated using system-managed cryptographic keys. Verified using a single, consistent trust boundary. The system does not delegate identity verification to external authorities and does not mix multiple identity sources at runtime. Equality of Human Identities Within a single running system: All human identities are verified in exactly the same way. No human role is inherently trusted. All human actions are cryptographically signed and auditable. Roles define permissions, not trust. Non-Repudiation All authoritative human actions are: Cryptographically signed. Verifiable by the system. Non-repudiable. The system can always prove: Who performed an action. What action was performed. Under which logic version it was evaluated. Insider Threat Model The system\u2019s threat model includes: External attackers. Malicious insiders. Multiple insiders colluding. No human role is assumed to be benign by default. Security mechanisms must ensure: All actions are fully auditable. Tampering is detectable. No group of humans can silently subvert system truth. Section 4 : Registry & Event Store Model (draft v1) Source of Truth The system maintains a logically single registry as its authoritative source of truth. All canonical records exist only within this registry. No component outside the registry is considered a source of truth. Append-Only Semantics The registry is strictly append-only. Once a record is written: It is never modified. It is never deleted. It is never overwritten. All system evolution occurs only by appending new records. Logical Singularity, Physical Distribution The registry is physically distributed across multiple replicas for availability and resilience. However, it behaves as a logically single source of truth. If replicas diverge, disagree, or cannot establish consistency: The system must fail closed. No new records may be accepted. Processing must stop until consistency is restored. Multiple Typed Logs The registry is organized as multiple explicit append-only logs. Each log corresponds to a distinct class of record, such as: Decision events. Execution traces. Escalation records. Change sets. Operational records. Logs are logically separate but causally linked through explicit references. No single unified log is used for all record types. Registry Authority Rule The Decision Engine must never write canonical records directly. All creation of canonical records occurs only via the Registry Engine. The Decision Engine is an orchestrator, not a source of truth. Section 5 : Canonical Record Types (draft v1) Closed Set Principle The system defines a strictly limited and closed set of canonical record types. Only these record types are permitted to exist in the registry. No new fundamental record types may be introduced dynamically. Changes to the set of record types are treated as system evolution and require explicit human approval. Factual Record Types The system includes the following factual record types: DecisionEvent ExecutionTrace EscalationRecord OperationalRecord These represent what actually happened in the system. They are immutable, append-only, and content-hash identified. Definitional Record Types The system includes the following definitional record types: DecisionPoint Precondition EscalationRule IntentSkeleton ChangeSet These represent the logic and structure that govern future behavior. They are immutable, append-only, and content-hash identified. Schema Strictness All canonical record types have strict, fully normalized schemas. For each record type: Only explicitly defined fields are allowed. Unknown or extension fields are forbidden. Records with invalid schema are rejected. Referential Integrity All canonical records must reference only existing canonical records. Records containing invalid, missing, or inconsistent references are invalid and must be rejected. Validation and Consensus A canonical record is considered valid only if: Its schema is valid. All references are valid. All required signatures are valid. All replicas reach unanimous consensus. If any of these conditions fail, the record must not be accepted. Section 6 : Decision Semantics (draft v1) Decision Definition A decision is any authoritative determination made by the system at a defined decision point. Every decision is recorded as a DecisionEvent. There is no special distinction between intermediate and final decisions. All decisions are first-class. Deterministic Evaluation For any given input, the system may only apply predefined, human-authored logic. The system must never infer, optimize, or compute outcomes not explicitly specified. If no deterministic outcome can be derived from written logic, the system must escalate to human authority. Decision Event Structure A DecisionEvent includes: The decision point at which it occurred. The intent context under which it was evaluated. The outcome selected. A structured reason code chosen from a human-defined enum. A reference to the execution trace on which it is based. Cryptographic signatures. A DecisionEvent does not include: Free-text justification. Embedded data. Explicit timestamps. Identity of the decision-maker. Reason Codes Reason codes represent categories of justification. They are controlled, human-defined enums. They do not contain explanations themselves. Full explanations are derived from execution traces and definitional logic. Temporal Semantics A DecisionEvent does not contain an explicit timestamp. Temporal ordering is derived from: Append-only ledger position. Cryptographic signatures. Time is not stored as semantic content inside the decision itself. Section 7 : Execution & Replay Semantics (draft v1) Execution Model System execution is represented as a sequence of immutable execution traces. Each ExecutionTrace represents a single step or transition in a decision process. Execution is append-only and strictly ordered by causal links between traces. Trace Immutability Each ExecutionTrace: Is created once. Is never modified. Is never deleted. References the previous trace in the process. There is no single growing or mutable trace object. The full execution history is the chain of trace records. Replay Semantics Replay is purely logical and internal. Its purpose is to reconstruct: What the system believed. What decisions were made. How those decisions were reached. Replay must never: Re-trigger external actions. Cause any real-world side effects. Modify system state. Escalation Semantics Escalations are first-class governed processes. An escalation is represented by an EscalationRecord, which includes: The trigger trace. The escalation rule used. The assigned human authorities. The human resolution. The resulting decision event. The resolution trace. Escalations are not mere notifications. They are authoritative decision processes with recorded outcomes. Causal Consistency All execution traces, decisions, and escalations must form a causally consistent graph. No cycles are permitted. Section 8 : Intent & Process Model (draft v1) Intent Context An IntentContext represents a single decision process instance. It is a snapshot of all relevant state for that process. Once a decision process starts, its IntentContext is frozen. No mid-flight input may mutate it. Snapshot Isolation If new information arrives while a decision is pending: Either a new decision process is spawned with a new IntentContext, or The current process is aborted and restarted. Inputs are never merged into an active context. Intent Skeleton An IntentSkeleton defines the executable behavioral template for a class of processes. It specifies: Default stages. Allowed transitions. Linked decision points. Linked preconditions. Linked escalation rules. An IntentSkeleton is not merely a static ontology. It is a starter program for how an intent should be processed. Process Determinism Intent processing is fully deterministic. Given the same IntentSkeleton and the same IntentContext, the system must always produce the same sequence of traces and decisions. Task Semantics A task is a notification or instruction issued to a human. Tasks are not first-class entities with their own lifecycle. The system records that a task was issued and to whom. Task execution is reflected only through subsequent human decisions or actions. Section 9 : Change & Evolution Model (draft v1) Non-Retroactivity System logic changes must never retroactively affect past decisions. Every decision is evaluated only against the exact logic version that existed at the time the decision process started. ChangeSet Mechanism All changes to definitional logic must be proposed and compiled into a ChangeSet artifact. The runtime system ingests and applies only ChangeSets. Direct mutation of core definitions is forbidden. Human Approval Each ChangeSet requires explicit human approval before application. Automatic application is not allowed. Single Active Version At any given time, there is exactly one active version of system schemas and logic. Old versions are preserved only for historical reference and replay. Multiple active logic versions may not coexist at runtime. Immutable History Past definitions are never deleted. They remain in the registry as historical truth. System evolution is fully auditable. Section 10 : Security & Threat Model (draft v1) Threat Model The system assumes the presence of: External attackers. Malicious insiders. Faulty or compromised internal components. Multiple insiders colluding. No internal actor is inherently trusted. Auditability All actions in the system must be: Recorded. Cryptographically verifiable. Fully auditable. No action may occur without leaving an immutable trace. Tamper Detection Tampering with any canonical record must be detectable. Record identity and integrity are cryptographically bound. Replay does not require trusting storage. Fail-Closed Principle If the system cannot establish: Consistent registry state, or Valid authority, or Valid cryptographic verification, It must fail closed and stop processing. No Silent Authority No human or system component may perform authoritative actions without being recorded and signed. There is no concept of implicit trust. All authority is explicit and auditable. Section 11 \u2014 Deployment & Operational Model (draft v1) 1. Physical Distribution The system is physically distributed across multiple independent replicas. Each replica runs as a separate program or process. There is no single monolithic system instance. Logical Singularity Despite physical distribution, the system behaves as a logically single entity. All replicas must agree on all canonical records. There is exactly one authoritative system state. Consensus Requirement The system uses strong consensus with unanimous agreement. A record is considered valid only if all replicas explicitly agree. Temporary forks or divergent truths are not permitted. Failure Semantics If replicas: Diverge, Disagree, or Cannot reach unanimous consensus, The system must stop processing and wait until consistency is restored. Availability is always secondary to correctness. Operational Records Operational events, both human and system-generated, are recorded as OperationalRecords. These records are first-class, immutable, and auditable. They are subject to the same cryptographic and consensus guarantees as all other canonical records. Section 12 : Global Invariants (draft v1) Determinism Invariant For any given input and logic version, the system must always produce the same sequence of execution traces and decisions. No nondeterministic behavior is permitted. Authority Invariant No authoritative outcome may be produced without explicit human-defined logic and, where required, explicit human approval. AI components may never act as autonomous authorities. Non-Retroactivity Invariant Past decisions must never be re-evaluated or altered by future logic changes. Historical truth is immutable. Identity Invariant All actions must be attributable to verified system identities. Anonymous authority is forbidden. Content-Derived Identity Invariant Every canonical record must have a content-derived cryptographic identity. Any change to content must result in a different identity. Fail-Closed Invariant If any core invariant cannot be enforced, the system must stop processing. Partial correctness is forbidden.","title":"Architecture v1"},{"location":"architecture_v1/#architecture-v1","text":"Section 1 : Purpose & Scope Purpose The system is a regulated deterministic governance platform designed to serve as a foundational decision backbone for organizations and critical processes. Its purpose is to: Execute decision processes using only explicit, human-authored logic. Record all authoritative decisions as immutable, auditable facts. Provide full, reconstructable explanations for every decision. Enforce strong human authority over all system evolution. Act as a safe boundary between automated reasoning and real-world action. The system is intended to be used as: A Decision Backbone for structured decision-making. A Compliance Engine for enforceable governance rules. A Legal Memory for authoritative, non-repudiable records. A Safe AI Boundary where AI may assist in design and simulation but never act as an autonomous authority. Scope The system governs decision logic, not general computation. It is scoped to: Deterministic evaluation of predefined decision processes. Human-in-the-loop escalation where deterministic outcomes cannot be derived. Cryptographically verifiable recording of decisions and processes. Logical replay and reconstruction of past decisions for audit and explanation. The system operates under the principle that no outcome may be produced unless it is explicitly permitted by prior human-authored logic. Out of Scope The system does not: Perform open-ended optimization or inference. Learn or modify its own decision logic. Generate new rules, policies, or outcomes autonomously. Act as a general-purpose workflow engine. Execute real-world actions directly without human authorization. AI components may be used only for design assistance, simulation, and explanation. They are never a source of authority and never a source of truth. Authority Boundary The system itself is the authoritative source of internal truth. However: All system behavior is defined and controlled by humans. All changes to system logic require explicit human approval. The system enforces its own constraints and must fail closed if consistency or authority cannot be established. The system is governed by humans, but not mutable by humans without trace. Section 2 : Core Ontology (draft v1) Ontological Scope The system defines a closed and explicit ontology of internal entities. Only entities defined within this ontology are permitted to exist inside the system. No implicit, dynamic, or ad-hoc entity types are allowed. All entities are: First-class. Explicitly typed. Immutable once created. Identified by content-derived cryptographic identity. Classes of Entities The system\u2019s ontology consists of two fundamental classes: a) Factual Entities Factual entities represent what actually happened. They include records such as: Decisions made by the system. Execution steps taken during a process. Escalations and their resolutions. Operational events. Factual entities are historical truth. They are never edited, never deleted, and never reinterpreted. b) Definitional Entities Definitional entities represent the logic that governs system behavior. They include records such as: Decision points. Preconditions. Escalation rules. Intent skeletons. Schemas and record definitions. Definitional entities determine how future decisions may be evaluated. They do not retroactively affect past factual entities. Ontology Closure Principle The set of entity types in the system is strictly limited and closed. No new fundamental entity types may be introduced dynamically. Changes to the ontology itself are treated as system evolution and require the same human-approved change process as any other core logic change. Dual-Truth Principle The system treats both: Facts (what happened), and Process traces (how it happened) as equally real and first-class. Neither is derived from the other. Both are stored explicitly, immutably, and independently. Identity Principle Every entity in the system has a content-derived cryptographic identity. The identity is computed as a hash of the canonical serialization of the entity\u2019s contents. Any change to content produces a different identity. Tampering is detectable at the object level. Replay does not require trusting storage. Section 3 : Authority & Identity Model (draft v1) Authority Model The system operates under a strict human authority model. No internal component, automated process, or AI system is ever considered an authority. All authoritative decisions originate from humans and are recorded explicitly by the system. The system may evaluate logic and enforce constraints, but it never originates authority. Identity Model The system itself is the ultimate authority for internal identity. All human identities are: Created and managed inside the system. Authenticated using system-managed cryptographic keys. Verified using a single, consistent trust boundary. The system does not delegate identity verification to external authorities and does not mix multiple identity sources at runtime. Equality of Human Identities Within a single running system: All human identities are verified in exactly the same way. No human role is inherently trusted. All human actions are cryptographically signed and auditable. Roles define permissions, not trust. Non-Repudiation All authoritative human actions are: Cryptographically signed. Verifiable by the system. Non-repudiable. The system can always prove: Who performed an action. What action was performed. Under which logic version it was evaluated. Insider Threat Model The system\u2019s threat model includes: External attackers. Malicious insiders. Multiple insiders colluding. No human role is assumed to be benign by default. Security mechanisms must ensure: All actions are fully auditable. Tampering is detectable. No group of humans can silently subvert system truth. Section 4 : Registry & Event Store Model (draft v1) Source of Truth The system maintains a logically single registry as its authoritative source of truth. All canonical records exist only within this registry. No component outside the registry is considered a source of truth. Append-Only Semantics The registry is strictly append-only. Once a record is written: It is never modified. It is never deleted. It is never overwritten. All system evolution occurs only by appending new records. Logical Singularity, Physical Distribution The registry is physically distributed across multiple replicas for availability and resilience. However, it behaves as a logically single source of truth. If replicas diverge, disagree, or cannot establish consistency: The system must fail closed. No new records may be accepted. Processing must stop until consistency is restored. Multiple Typed Logs The registry is organized as multiple explicit append-only logs. Each log corresponds to a distinct class of record, such as: Decision events. Execution traces. Escalation records. Change sets. Operational records. Logs are logically separate but causally linked through explicit references. No single unified log is used for all record types. Registry Authority Rule The Decision Engine must never write canonical records directly. All creation of canonical records occurs only via the Registry Engine. The Decision Engine is an orchestrator, not a source of truth. Section 5 : Canonical Record Types (draft v1) Closed Set Principle The system defines a strictly limited and closed set of canonical record types. Only these record types are permitted to exist in the registry. No new fundamental record types may be introduced dynamically. Changes to the set of record types are treated as system evolution and require explicit human approval. Factual Record Types The system includes the following factual record types: DecisionEvent ExecutionTrace EscalationRecord OperationalRecord These represent what actually happened in the system. They are immutable, append-only, and content-hash identified. Definitional Record Types The system includes the following definitional record types: DecisionPoint Precondition EscalationRule IntentSkeleton ChangeSet These represent the logic and structure that govern future behavior. They are immutable, append-only, and content-hash identified. Schema Strictness All canonical record types have strict, fully normalized schemas. For each record type: Only explicitly defined fields are allowed. Unknown or extension fields are forbidden. Records with invalid schema are rejected. Referential Integrity All canonical records must reference only existing canonical records. Records containing invalid, missing, or inconsistent references are invalid and must be rejected. Validation and Consensus A canonical record is considered valid only if: Its schema is valid. All references are valid. All required signatures are valid. All replicas reach unanimous consensus. If any of these conditions fail, the record must not be accepted. Section 6 : Decision Semantics (draft v1) Decision Definition A decision is any authoritative determination made by the system at a defined decision point. Every decision is recorded as a DecisionEvent. There is no special distinction between intermediate and final decisions. All decisions are first-class. Deterministic Evaluation For any given input, the system may only apply predefined, human-authored logic. The system must never infer, optimize, or compute outcomes not explicitly specified. If no deterministic outcome can be derived from written logic, the system must escalate to human authority. Decision Event Structure A DecisionEvent includes: The decision point at which it occurred. The intent context under which it was evaluated. The outcome selected. A structured reason code chosen from a human-defined enum. A reference to the execution trace on which it is based. Cryptographic signatures. A DecisionEvent does not include: Free-text justification. Embedded data. Explicit timestamps. Identity of the decision-maker. Reason Codes Reason codes represent categories of justification. They are controlled, human-defined enums. They do not contain explanations themselves. Full explanations are derived from execution traces and definitional logic. Temporal Semantics A DecisionEvent does not contain an explicit timestamp. Temporal ordering is derived from: Append-only ledger position. Cryptographic signatures. Time is not stored as semantic content inside the decision itself. Section 7 : Execution & Replay Semantics (draft v1) Execution Model System execution is represented as a sequence of immutable execution traces. Each ExecutionTrace represents a single step or transition in a decision process. Execution is append-only and strictly ordered by causal links between traces. Trace Immutability Each ExecutionTrace: Is created once. Is never modified. Is never deleted. References the previous trace in the process. There is no single growing or mutable trace object. The full execution history is the chain of trace records. Replay Semantics Replay is purely logical and internal. Its purpose is to reconstruct: What the system believed. What decisions were made. How those decisions were reached. Replay must never: Re-trigger external actions. Cause any real-world side effects. Modify system state. Escalation Semantics Escalations are first-class governed processes. An escalation is represented by an EscalationRecord, which includes: The trigger trace. The escalation rule used. The assigned human authorities. The human resolution. The resulting decision event. The resolution trace. Escalations are not mere notifications. They are authoritative decision processes with recorded outcomes. Causal Consistency All execution traces, decisions, and escalations must form a causally consistent graph. No cycles are permitted. Section 8 : Intent & Process Model (draft v1) Intent Context An IntentContext represents a single decision process instance. It is a snapshot of all relevant state for that process. Once a decision process starts, its IntentContext is frozen. No mid-flight input may mutate it. Snapshot Isolation If new information arrives while a decision is pending: Either a new decision process is spawned with a new IntentContext, or The current process is aborted and restarted. Inputs are never merged into an active context. Intent Skeleton An IntentSkeleton defines the executable behavioral template for a class of processes. It specifies: Default stages. Allowed transitions. Linked decision points. Linked preconditions. Linked escalation rules. An IntentSkeleton is not merely a static ontology. It is a starter program for how an intent should be processed. Process Determinism Intent processing is fully deterministic. Given the same IntentSkeleton and the same IntentContext, the system must always produce the same sequence of traces and decisions. Task Semantics A task is a notification or instruction issued to a human. Tasks are not first-class entities with their own lifecycle. The system records that a task was issued and to whom. Task execution is reflected only through subsequent human decisions or actions. Section 9 : Change & Evolution Model (draft v1) Non-Retroactivity System logic changes must never retroactively affect past decisions. Every decision is evaluated only against the exact logic version that existed at the time the decision process started. ChangeSet Mechanism All changes to definitional logic must be proposed and compiled into a ChangeSet artifact. The runtime system ingests and applies only ChangeSets. Direct mutation of core definitions is forbidden. Human Approval Each ChangeSet requires explicit human approval before application. Automatic application is not allowed. Single Active Version At any given time, there is exactly one active version of system schemas and logic. Old versions are preserved only for historical reference and replay. Multiple active logic versions may not coexist at runtime. Immutable History Past definitions are never deleted. They remain in the registry as historical truth. System evolution is fully auditable. Section 10 : Security & Threat Model (draft v1) Threat Model The system assumes the presence of: External attackers. Malicious insiders. Faulty or compromised internal components. Multiple insiders colluding. No internal actor is inherently trusted. Auditability All actions in the system must be: Recorded. Cryptographically verifiable. Fully auditable. No action may occur without leaving an immutable trace. Tamper Detection Tampering with any canonical record must be detectable. Record identity and integrity are cryptographically bound. Replay does not require trusting storage. Fail-Closed Principle If the system cannot establish: Consistent registry state, or Valid authority, or Valid cryptographic verification, It must fail closed and stop processing. No Silent Authority No human or system component may perform authoritative actions without being recorded and signed. There is no concept of implicit trust. All authority is explicit and auditable. Section 11 \u2014 Deployment & Operational Model (draft v1) 1. Physical Distribution The system is physically distributed across multiple independent replicas. Each replica runs as a separate program or process. There is no single monolithic system instance. Logical Singularity Despite physical distribution, the system behaves as a logically single entity. All replicas must agree on all canonical records. There is exactly one authoritative system state. Consensus Requirement The system uses strong consensus with unanimous agreement. A record is considered valid only if all replicas explicitly agree. Temporary forks or divergent truths are not permitted. Failure Semantics If replicas: Diverge, Disagree, or Cannot reach unanimous consensus, The system must stop processing and wait until consistency is restored. Availability is always secondary to correctness. Operational Records Operational events, both human and system-generated, are recorded as OperationalRecords. These records are first-class, immutable, and auditable. They are subject to the same cryptographic and consensus guarantees as all other canonical records. Section 12 : Global Invariants (draft v1) Determinism Invariant For any given input and logic version, the system must always produce the same sequence of execution traces and decisions. No nondeterministic behavior is permitted. Authority Invariant No authoritative outcome may be produced without explicit human-defined logic and, where required, explicit human approval. AI components may never act as autonomous authorities. Non-Retroactivity Invariant Past decisions must never be re-evaluated or altered by future logic changes. Historical truth is immutable. Identity Invariant All actions must be attributable to verified system identities. Anonymous authority is forbidden. Content-Derived Identity Invariant Every canonical record must have a content-derived cryptographic identity. Any change to content must result in a different identity. Fail-Closed Invariant If any core invariant cannot be enforced, the system must stop processing. Partial correctness is forbidden.","title":"Architecture v1"},{"location":"axioms/","text":"Axioms Foundational Axioms of the Governance System Axiom 1 : Determinism For any given input and logic version, the system must always produce the same sequence of execution traces and decisions. No nondeterministic behavior is permitted. Axiom 2 : Human Authority All authority originates from humans. No internal component, automated process, or AI system is ever an authority. The system may evaluate and enforce logic, but it never originates authority. Axiom 3 : Explicit Logic Only The system may only apply logic that has been explicitly authored and approved by humans. The system must never infer, optimize, or invent outcomes. If no deterministic outcome exists, the system must escalate to humans. Axiom 4 : Immutable History All canonical records are immutable. Past decisions, traces, and definitions must never be modified or deleted. Historical truth is permanent. Axiom 5 : Non-Retroactivity System logic changes must never retroactively affect past decisions. Every decision is evaluated only against the logic version that existed when its process started. Axiom 6 : Content-Derived Identity Every canonical record has a content-derived cryptographic identity. Any change to content produces a different identity. Tampering is always detectable. Axiom 7 : Closed Ontology Only explicitly defined entity and record types may exist in the system. No implicit, dynamic, or ad-hoc types are permitted. Axiom 8 : Append-Only Truth All system evolution occurs by appending new records. No record may ever be overwritten or erased. Axiom 9 : Full Auditability All actions in the system must leave an immutable, verifiable trace. No silent or hidden authority is permitted. Axiom 10 : Fail-Closed If the system cannot establish: valid authority, valid logic, or consistent truth, it must stop processing. Partial correctness is forbidden.","title":"Axioms"},{"location":"axioms/#axioms","text":"Foundational Axioms of the Governance System Axiom 1 : Determinism For any given input and logic version, the system must always produce the same sequence of execution traces and decisions. No nondeterministic behavior is permitted. Axiom 2 : Human Authority All authority originates from humans. No internal component, automated process, or AI system is ever an authority. The system may evaluate and enforce logic, but it never originates authority. Axiom 3 : Explicit Logic Only The system may only apply logic that has been explicitly authored and approved by humans. The system must never infer, optimize, or invent outcomes. If no deterministic outcome exists, the system must escalate to humans. Axiom 4 : Immutable History All canonical records are immutable. Past decisions, traces, and definitions must never be modified or deleted. Historical truth is permanent. Axiom 5 : Non-Retroactivity System logic changes must never retroactively affect past decisions. Every decision is evaluated only against the logic version that existed when its process started. Axiom 6 : Content-Derived Identity Every canonical record has a content-derived cryptographic identity. Any change to content produces a different identity. Tampering is always detectable. Axiom 7 : Closed Ontology Only explicitly defined entity and record types may exist in the system. No implicit, dynamic, or ad-hoc types are permitted. Axiom 8 : Append-Only Truth All system evolution occurs by appending new records. No record may ever be overwritten or erased. Axiom 9 : Full Auditability All actions in the system must leave an immutable, verifiable trace. No silent or hidden authority is permitted. Axiom 10 : Fail-Closed If the system cannot establish: valid authority, valid logic, or consistent truth, it must stop processing. Partial correctness is forbidden.","title":"Axioms"},{"location":"contact/","text":"Contact This is a commercial governance infrastructure product designed for deployment in regulated and high\u2011consequence environments. We work with organizations that are concerned with safety, accountability, and decision authority in AI\u2011powered systems. Who should contact us Contact us if you are responsible for regulatory compliance, risk, safety, or decision governance within your organization. This may be a dedicated function or a single team embedded within a larger enterprise. Typical roles and teams include: compliance, regulatory affairs, or risk management AI governance, model risk, or responsible AI teams security, safety, or internal audit functions legal, policy, or enterprise architecture groups founders or technical leaders accountable for regulated deployments investors and funds focused on deep-tech, infrastructure, or governance-critical systems government bodies or public-sector institutions interested in supporting, piloting, or advancing deterministic governance for AI You do not need to represent the entire organization. Engagement often starts with one department or accountable owner tasked with making AI systems defensible. How we are different We build decision authority infrastructure . Our work focuses on: separating AI intelligence from decision authority enforcing deterministic, auditable decision logic making authority explicit, attributable, and contestable ensuring AI can be deployed in regulated environments without becoming a source of uncontrolled power If your concern is not model performance, but who is allowed to decide, why, and under what authority , then this is the right place to engage. How to contact Email LinkedIn Website","title":"Contact"},{"location":"contact/#contact","text":"This is a commercial governance infrastructure product designed for deployment in regulated and high\u2011consequence environments. We work with organizations that are concerned with safety, accountability, and decision authority in AI\u2011powered systems.","title":"Contact"},{"location":"contact/#who-should-contact-us","text":"Contact us if you are responsible for regulatory compliance, risk, safety, or decision governance within your organization. This may be a dedicated function or a single team embedded within a larger enterprise. Typical roles and teams include: compliance, regulatory affairs, or risk management AI governance, model risk, or responsible AI teams security, safety, or internal audit functions legal, policy, or enterprise architecture groups founders or technical leaders accountable for regulated deployments investors and funds focused on deep-tech, infrastructure, or governance-critical systems government bodies or public-sector institutions interested in supporting, piloting, or advancing deterministic governance for AI You do not need to represent the entire organization. Engagement often starts with one department or accountable owner tasked with making AI systems defensible.","title":"Who should contact us"},{"location":"contact/#how-we-are-different","text":"We build decision authority infrastructure . Our work focuses on: separating AI intelligence from decision authority enforcing deterministic, auditable decision logic making authority explicit, attributable, and contestable ensuring AI can be deployed in regulated environments without becoming a source of uncontrolled power If your concern is not model performance, but who is allowed to decide, why, and under what authority , then this is the right place to engage.","title":"How we are different"},{"location":"contact/#how-to-contact","text":"Email LinkedIn Website","title":"How to contact"},{"location":"engine/","text":"Engine Execution & Decision Engine Semantics Engine Role The Decision Engine is an orchestrator. It evaluates logic, produces execution traces, and triggers record creation. It is not a source of truth. It must never write canonical records directly. All canonical record creation occurs via the Registry Engine. Execution Model System execution is represented as a sequence of immutable ExecutionTraces. Each ExecutionTrace represents a single step or transition in a decision process. Execution is append-only and strictly ordered by causal links. There is no mutable global state. Intent Processing Each process begins with creation of an IntentContext. The IntentContext is a frozen snapshot of all relevant input. Once created: It cannot be modified. New inputs cannot be merged. Mid-flight changes require new processes. Deterministic Evaluation For any given IntentContext and logic version: The same execution traces must be produced. The same decisions must be produced. The engine must never: Infer missing logic. Optimize behavior. Invent outcomes. If deterministic evaluation is impossible, the engine must escalate. Decision Emission When a decision point is reached: The engine selects exactly one outcome. A DecisionEvent is produced. A reason code is attached. The decision references the final execution trace. There is no distinction between intermediate and final decisions. Replay Semantics Replay is purely logical and internal. Its purpose is to reconstruct: What the system believed. What steps occurred. How decisions were derived. Replay must never: Trigger external actions. Cause side effects. Modify system state. Failure Semantics If the engine cannot establish: Valid logic, Valid authority, Or valid registry state, It must stop processing. Partial execution is forbidden. Engine Constraints The engine must: Be deterministic. Be stateless between processes. Rely only on registry truth. Fail closed on inconsistency.","title":"Engine"},{"location":"engine/#engine","text":"Execution & Decision Engine Semantics Engine Role The Decision Engine is an orchestrator. It evaluates logic, produces execution traces, and triggers record creation. It is not a source of truth. It must never write canonical records directly. All canonical record creation occurs via the Registry Engine. Execution Model System execution is represented as a sequence of immutable ExecutionTraces. Each ExecutionTrace represents a single step or transition in a decision process. Execution is append-only and strictly ordered by causal links. There is no mutable global state. Intent Processing Each process begins with creation of an IntentContext. The IntentContext is a frozen snapshot of all relevant input. Once created: It cannot be modified. New inputs cannot be merged. Mid-flight changes require new processes. Deterministic Evaluation For any given IntentContext and logic version: The same execution traces must be produced. The same decisions must be produced. The engine must never: Infer missing logic. Optimize behavior. Invent outcomes. If deterministic evaluation is impossible, the engine must escalate. Decision Emission When a decision point is reached: The engine selects exactly one outcome. A DecisionEvent is produced. A reason code is attached. The decision references the final execution trace. There is no distinction between intermediate and final decisions. Replay Semantics Replay is purely logical and internal. Its purpose is to reconstruct: What the system believed. What steps occurred. How decisions were derived. Replay must never: Trigger external actions. Cause side effects. Modify system state. Failure Semantics If the engine cannot establish: Valid logic, Valid authority, Or valid registry state, It must stop processing. Partial execution is forbidden. Engine Constraints The engine must: Be deterministic. Be stateless between processes. Rely only on registry truth. Fail closed on inconsistency.","title":"Engine"},{"location":"escalation/","text":"Escalation Human Escalation & Authority Semantics Purpose of Escalation Escalation exists to handle cases where: Deterministic logic cannot derive an outcome. Human judgment is explicitly required. Authority must be exercised outside predefined rules. Escalation is not an error state. It is a first-class governed decision process. Escalation Trigger Escalation occurs when: A Precondition cannot be evaluated deterministically, or An EscalationRule\u2019s trigger_condition evaluates to true. The Decision Engine must never guess or approximate outcomes. If logic is insufficient, escalation is mandatory. Escalation Rule An EscalationRule defines: When escalation is triggered. Which human role(s) must be involved. Escalation rules are deterministic and human-authored. They are part of the system\u2019s definitional logic. Escalation Process When escalation is triggered: An EscalationRecord is created. Assigned humans are notified. Humans review the context and execution traces. A human resolution is provided. A resolution ExecutionTrace is created. A DecisionEvent is emitted based on the human outcome. The entire escalation lifecycle is recorded immutably. Human Authority Human participants in escalation: Are verified system identities. Must cryptographically sign their actions. Are fully auditable and non-repudiable. Human resolution is authoritative. The system may not override or reinterpret it. No Silent Escalation All escalations must be explicit. There is no concept of: Implicit human approval. Default fallback authority. Silent overrides. If a human decision occurs, it must be recorded. Escalation as Governance Escalation is not a workaround. It is the formal mechanism by which: The system remains safe. Responsibility remains human. Automation remains bounded. Escalation is the system\u2019s legal interface with reality.","title":"Escalation"},{"location":"escalation/#escalation","text":"Human Escalation & Authority Semantics Purpose of Escalation Escalation exists to handle cases where: Deterministic logic cannot derive an outcome. Human judgment is explicitly required. Authority must be exercised outside predefined rules. Escalation is not an error state. It is a first-class governed decision process. Escalation Trigger Escalation occurs when: A Precondition cannot be evaluated deterministically, or An EscalationRule\u2019s trigger_condition evaluates to true. The Decision Engine must never guess or approximate outcomes. If logic is insufficient, escalation is mandatory. Escalation Rule An EscalationRule defines: When escalation is triggered. Which human role(s) must be involved. Escalation rules are deterministic and human-authored. They are part of the system\u2019s definitional logic. Escalation Process When escalation is triggered: An EscalationRecord is created. Assigned humans are notified. Humans review the context and execution traces. A human resolution is provided. A resolution ExecutionTrace is created. A DecisionEvent is emitted based on the human outcome. The entire escalation lifecycle is recorded immutably. Human Authority Human participants in escalation: Are verified system identities. Must cryptographically sign their actions. Are fully auditable and non-repudiable. Human resolution is authoritative. The system may not override or reinterpret it. No Silent Escalation All escalations must be explicit. There is no concept of: Implicit human approval. Default fallback authority. Silent overrides. If a human decision occurs, it must be recorded. Escalation as Governance Escalation is not a workaround. It is the formal mechanism by which: The system remains safe. Responsibility remains human. Automation remains bounded. Escalation is the system\u2019s legal interface with reality.","title":"Escalation"},{"location":"examples_v1/","text":"Examples v1 Example Execution Traces for architecture_v1 Example 1 : Simple Deterministic Decision Scenario A system evaluates whether an action is permitted. IntentSkeleton Name: \"PermissionCheck\" IntentContext Input: - actor_id = Human_123 - action = \"ACCESS_RESOURCE\" Execution ExecutionTrace T1: System evaluates Precondition \"IsActorAuthenticated\" \u2192 true ExecutionTrace T2: System evaluates Precondition \"HasPermission\" \u2192 true DecisionEvent D1: decision_point = \"PermissionDecision\" outcome = \"ALLOW\" reason_code = \"ALL_PRECONDITIONS_TRUE\" based_on_trace = T2 Result Access is granted. No escalation occurs. Example 2 : Escalation Required Scenario A system cannot derive deterministic outcome. IntentSkeleton Name: \"FinancialApproval\" IntentContext Input: - amount = 1,000,000 - requester = Human_456 Execution ExecutionTrace T1: System evaluates Precondition \"AmountBelowLimit\" \u2192 false EscalationRecord E1: triggered_by = T1 escalation_rule = \"HighValueRequiresHuman\" assigned_humans = [Human_Admin] Human_Admin approves. ExecutionTrace T2: Human resolution recorded. DecisionEvent D1: decision_point = \"ApprovalDecision\" outcome = \"APPROVED\" reason_code = \"HUMAN_ESCALATION\" based_on_trace = T2 Result Decision produced via escalation. Example 3 : Snapshot Isolation Scenario New input arrives mid-decision. Execution IntentContext C1 created. ExecutionTrace T1 occurs. New input arrives. System behavior: - C1 remains unchanged. - New IntentContext C2 is created. C1 and C2 are evaluated independently.","title":"Examples v1"},{"location":"examples_v1/#examples-v1","text":"Example Execution Traces for architecture_v1","title":"Examples v1"},{"location":"examples_v1/#example-1-simple-deterministic-decision","text":"","title":"Example 1 : Simple Deterministic Decision"},{"location":"examples_v1/#scenario","text":"A system evaluates whether an action is permitted.","title":"Scenario"},{"location":"examples_v1/#intentskeleton","text":"Name: \"PermissionCheck\"","title":"IntentSkeleton"},{"location":"examples_v1/#intentcontext","text":"Input: - actor_id = Human_123 - action = \"ACCESS_RESOURCE\"","title":"IntentContext"},{"location":"examples_v1/#execution","text":"ExecutionTrace T1: System evaluates Precondition \"IsActorAuthenticated\" \u2192 true ExecutionTrace T2: System evaluates Precondition \"HasPermission\" \u2192 true DecisionEvent D1: decision_point = \"PermissionDecision\" outcome = \"ALLOW\" reason_code = \"ALL_PRECONDITIONS_TRUE\" based_on_trace = T2","title":"Execution"},{"location":"examples_v1/#result","text":"Access is granted. No escalation occurs.","title":"Result"},{"location":"examples_v1/#example-2-escalation-required","text":"","title":"Example 2 : Escalation Required"},{"location":"examples_v1/#scenario_1","text":"A system cannot derive deterministic outcome.","title":"Scenario"},{"location":"examples_v1/#intentskeleton_1","text":"Name: \"FinancialApproval\"","title":"IntentSkeleton"},{"location":"examples_v1/#intentcontext_1","text":"Input: - amount = 1,000,000 - requester = Human_456","title":"IntentContext"},{"location":"examples_v1/#execution_1","text":"ExecutionTrace T1: System evaluates Precondition \"AmountBelowLimit\" \u2192 false EscalationRecord E1: triggered_by = T1 escalation_rule = \"HighValueRequiresHuman\" assigned_humans = [Human_Admin] Human_Admin approves. ExecutionTrace T2: Human resolution recorded. DecisionEvent D1: decision_point = \"ApprovalDecision\" outcome = \"APPROVED\" reason_code = \"HUMAN_ESCALATION\" based_on_trace = T2","title":"Execution"},{"location":"examples_v1/#result_1","text":"Decision produced via escalation.","title":"Result"},{"location":"examples_v1/#example-3-snapshot-isolation","text":"","title":"Example 3 : Snapshot Isolation"},{"location":"examples_v1/#scenario_2","text":"New input arrives mid-decision.","title":"Scenario"},{"location":"examples_v1/#execution_2","text":"IntentContext C1 created. ExecutionTrace T1 occurs. New input arrives. System behavior: - C1 remains unchanged. - New IntentContext C2 is created. C1 and C2 are evaluated independently.","title":"Execution"},{"location":"glossary/","text":"Glossary This glossary defines all canonical terms used in the governance system. All terms are precise and non-interchangeable. DecisionPoint A formally defined location in a process where a decision must occur. DecisionPoints define the finite set of allowed outcomes. DecisionEvent A canonical record representing the authoritative outcome of a DecisionPoint. DecisionEvents are immutable and content-hash identified. ExecutionTrace An immutable record of a single step or transition in a process. ExecutionTraces form a causal chain. Escalation A governed transfer of authority to humans when logic is insufficient. EscalationRecord A record representing the full lifecycle of an escalation, including trigger, assigned humans, and resolution. ChangeSet A human-approved modification to system logic. All system evolution occurs only through ChangeSets. Precondition A pure boolean predicate over IntentContext. Preconditions have no side effects. IntentSkeleton An executable template defining the structure of a class of intents. Registry The append-only canonical store of all records. The single source of truth. Determinism The property that identical inputs always produce identical outcomes. Fail Closed The rule that the system must stop operating if consistency cannot be guaranteed.","title":"Glossary"},{"location":"glossary/#glossary","text":"This glossary defines all canonical terms used in the governance system. All terms are precise and non-interchangeable.","title":"Glossary"},{"location":"glossary/#decisionpoint","text":"A formally defined location in a process where a decision must occur. DecisionPoints define the finite set of allowed outcomes.","title":"DecisionPoint"},{"location":"glossary/#decisionevent","text":"A canonical record representing the authoritative outcome of a DecisionPoint. DecisionEvents are immutable and content-hash identified.","title":"DecisionEvent"},{"location":"glossary/#executiontrace","text":"An immutable record of a single step or transition in a process. ExecutionTraces form a causal chain.","title":"ExecutionTrace"},{"location":"glossary/#escalation","text":"A governed transfer of authority to humans when logic is insufficient.","title":"Escalation"},{"location":"glossary/#escalationrecord","text":"A record representing the full lifecycle of an escalation, including trigger, assigned humans, and resolution.","title":"EscalationRecord"},{"location":"glossary/#changeset","text":"A human-approved modification to system logic. All system evolution occurs only through ChangeSets.","title":"ChangeSet"},{"location":"glossary/#precondition","text":"A pure boolean predicate over IntentContext. Preconditions have no side effects.","title":"Precondition"},{"location":"glossary/#intentskeleton","text":"An executable template defining the structure of a class of intents.","title":"IntentSkeleton"},{"location":"glossary/#registry","text":"The append-only canonical store of all records. The single source of truth.","title":"Registry"},{"location":"glossary/#determinism","text":"The property that identical inputs always produce identical outcomes.","title":"Determinism"},{"location":"glossary/#fail-closed","text":"The rule that the system must stop operating if consistency cannot be guaranteed.","title":"Fail Closed"},{"location":"governance_principles/","text":"Governance Principles These principles define how the system must behave at all times. They are higher-level than axioms and guide all design decisions. 1. Explicit Over implicit All system behavior must be explicitly defined by humans. No hidden inference or emergent logic is allowed. 2. Human judgment over automation Automation may assist, but never replace, human authority. 3. Determinism over optimization Correctness and reproducibility take precedence over efficiency. 4. Auditability over performance Every action must be traceable and explainable. 5. Stability over innovation System evolution is slow, deliberate, and conservative. 6. Explanation over opacity Every outcome must be explainable from recorded logic. 7. Law over learning The system follows written rules, not learned behavior. 8. Fail closed by default On ambiguity, inconsistency, or missing logic, the system must halt and escalate. 9. No silent drift System behavior must never change without a ChangeSet. 10. Authority is always provable All decisions must be cryptographically attributable.","title":"Governance Principles"},{"location":"governance_principles/#governance-principles","text":"These principles define how the system must behave at all times. They are higher-level than axioms and guide all design decisions.","title":"Governance Principles"},{"location":"governance_principles/#1-explicit-over-implicit","text":"All system behavior must be explicitly defined by humans. No hidden inference or emergent logic is allowed.","title":"1. Explicit Over implicit"},{"location":"governance_principles/#2-human-judgment-over-automation","text":"Automation may assist, but never replace, human authority.","title":"2. Human judgment over automation"},{"location":"governance_principles/#3-determinism-over-optimization","text":"Correctness and reproducibility take precedence over efficiency.","title":"3. Determinism over optimization"},{"location":"governance_principles/#4-auditability-over-performance","text":"Every action must be traceable and explainable.","title":"4. Auditability over performance"},{"location":"governance_principles/#5-stability-over-innovation","text":"System evolution is slow, deliberate, and conservative.","title":"5. Stability over innovation"},{"location":"governance_principles/#6-explanation-over-opacity","text":"Every outcome must be explainable from recorded logic.","title":"6. Explanation over opacity"},{"location":"governance_principles/#7-law-over-learning","text":"The system follows written rules, not learned behavior.","title":"7. Law over learning"},{"location":"governance_principles/#8-fail-closed-by-default","text":"On ambiguity, inconsistency, or missing logic, the system must halt and escalate.","title":"8. Fail closed by default"},{"location":"governance_principles/#9-no-silent-drift","text":"System behavior must never change without a ChangeSet.","title":"9. No silent drift"},{"location":"governance_principles/#10-authority-is-always-provable","text":"All decisions must be cryptographically attributable.","title":"10. Authority is always provable"},{"location":"newsletter/","text":"How to Subscribe The official newsletter is hosted on Substack . Subscribe here","title":"Newsletter"},{"location":"newsletter/#how-to-subscribe","text":"The official newsletter is hosted on Substack . Subscribe here","title":"How to Subscribe"},{"location":"ontology/","text":"Ontology Core Ontology of the Governance System Ontological Scope The system defines a closed and explicit ontology of internal entities. Only entities defined within this ontology are permitted to exist inside the system. No implicit, dynamic, or ad-hoc entity types are allowed. All entities are: First-class. Explicitly typed. Immutable once created. Identified by content-derived cryptographic identity. Fundamental Classes The system\u2019s ontology consists of two fundamental classes: 2.1 Factual Entities Factual entities represent what actually happened. They include: Decisions made by the system. Execution steps taken during a process. Escalations and their resolutions. Operational events. Factual entities are historical truth. They are never edited, never deleted, and never reinterpreted. 2.2 Definitional Entities Definitional entities represent the logic that governs system behavior. They include: Decision points. Preconditions. Escalation rules. Intent skeletons. Record schemas. Definitional entities determine how future decisions may be evaluated. They do not retroactively affect past factual entities. Ontology Closure Principle The set of entity types in the system is strictly limited and closed. No new fundamental entity types may be introduced dynamically. Changes to the ontology itself require the same human-approved change process as any other core logic change. Dual-Truth Principle The system treats both: Facts (what happened), and Process traces (how it happened) as equally real and first-class. Neither is derived from the other. Both are stored explicitly, immutably, and independently. Identity Principle Every entity in the system has a content-derived cryptographic identity. The identity is computed as a hash of the canonical serialization of the entity\u2019s contents. Any change to content produces a different identity. Tampering is detectable at the object level. Replay does not require trusting storage.","title":"Ontology"},{"location":"ontology/#ontology","text":"Core Ontology of the Governance System Ontological Scope The system defines a closed and explicit ontology of internal entities. Only entities defined within this ontology are permitted to exist inside the system. No implicit, dynamic, or ad-hoc entity types are allowed. All entities are: First-class. Explicitly typed. Immutable once created. Identified by content-derived cryptographic identity. Fundamental Classes The system\u2019s ontology consists of two fundamental classes: 2.1 Factual Entities Factual entities represent what actually happened. They include: Decisions made by the system. Execution steps taken during a process. Escalations and their resolutions. Operational events. Factual entities are historical truth. They are never edited, never deleted, and never reinterpreted. 2.2 Definitional Entities Definitional entities represent the logic that governs system behavior. They include: Decision points. Preconditions. Escalation rules. Intent skeletons. Record schemas. Definitional entities determine how future decisions may be evaluated. They do not retroactively affect past factual entities. Ontology Closure Principle The set of entity types in the system is strictly limited and closed. No new fundamental entity types may be introduced dynamically. Changes to the ontology itself require the same human-approved change process as any other core logic change. Dual-Truth Principle The system treats both: Facts (what happened), and Process traces (how it happened) as equally real and first-class. Neither is derived from the other. Both are stored explicitly, immutably, and independently. Identity Principle Every entity in the system has a content-derived cryptographic identity. The identity is computed as a hash of the canonical serialization of the entity\u2019s contents. Any change to content produces a different identity. Tampering is detectable at the object level. Replay does not require trusting storage.","title":"Ontology"},{"location":"records/","text":"Records Canonical Record Types 1. Closed Set Principle The system defines a strictly limited and closed set of canonical record types. Only these record types are permitted to exist in the registry. No new fundamental record types may be introduced dynamically. Changes to the set of record types require explicit human approval via ChangeSets. 2. Factual Record Types These records represent what actually happened. 2.1 DecisionEvent Represents an authoritative decision. Fields: - decision_point_id : Hash - intent_context_id : Hash - outcome : Enum - reason_code : Enum - based_on_trace_id : Hash - signatures : List Properties: - No free-text fields. - No timestamps. - No decider identity. - Immutable and append-only. 2.2 ExecutionTrace Represents a single step in a decision process. Fields: - intent_context_id : Hash - trace_type : Enum - subject_id : Hash - previous_trace_id : Hash | null - resulting_context_id : Hash - signatures : List Properties: - Each trace references the previous. - No cycles allowed. - Entire history is the chain. 2.3 EscalationRecord Represents a governed human escalation. Fields: - trigger_trace_id : Hash - escalation_rule_id : Hash - assigned_humans : List - resolution_decision_event_id : Hash - resolution_trace_id : Hash - signatures : List Properties: - Records full escalation lifecycle. - First-class authoritative process. 2.4 OperationalRecord Represents operational system or human events. Fields: - operation_type : Enum - operation_actor : Enum(HUMAN|SYSTEM) - actor_identity_id : Hash - affected_components : List - operation_payload : DeterministicObject - signatures : List 3. Definitional Record Types These records define how future behavior works. 3.1 DecisionPoint Defines a place where a decision occurs. Fields: - name : String - description : String - outcomes : List - signatures : List 3.2 Precondition Defines a boolean predicate. Fields: - name : String - description : String - predicate_expression : BooleanExpression - signatures : List Properties: - Must be deterministic. - No side effects. 3.3 EscalationRule Defines when human escalation occurs. Fields: - name : String - description : String - trigger_condition : BooleanExpression - escalation_target_role : Role - signatures : List 3.4 IntentSkeleton Defines a behavioral template. Fields: - name : String - description : String - stages : List - transitions : List - signatures : List 3.5 ChangeSet Defines a change to system logic. Fields: - change_type : Enum(ADD|UPDATE|DEPRECATE) - target_record_type : Enum - target_record_id : Hash - new_definition : Record - rationale : String - approvals : List - signatures : List 4. Referential Integrity All canonical records must reference only existing canonical records. Records with invalid references are rejected. 5. Validation & Consensus A canonical record is valid only if: - Schema is valid. - References are valid. - Required signatures are present. - All replicas reach unanimous consensus.","title":"Records"},{"location":"records/#records","text":"Canonical Record Types","title":"Records"},{"location":"records/#1-closed-set-principle","text":"The system defines a strictly limited and closed set of canonical record types. Only these record types are permitted to exist in the registry. No new fundamental record types may be introduced dynamically. Changes to the set of record types require explicit human approval via ChangeSets.","title":"1. Closed Set Principle"},{"location":"records/#2-factual-record-types","text":"These records represent what actually happened.","title":"2. Factual Record Types"},{"location":"records/#21-decisionevent","text":"Represents an authoritative decision. Fields: - decision_point_id : Hash - intent_context_id : Hash - outcome : Enum - reason_code : Enum - based_on_trace_id : Hash - signatures : List Properties: - No free-text fields. - No timestamps. - No decider identity. - Immutable and append-only.","title":"2.1 DecisionEvent"},{"location":"records/#22-executiontrace","text":"Represents a single step in a decision process. Fields: - intent_context_id : Hash - trace_type : Enum - subject_id : Hash - previous_trace_id : Hash | null - resulting_context_id : Hash - signatures : List Properties: - Each trace references the previous. - No cycles allowed. - Entire history is the chain.","title":"2.2 ExecutionTrace"},{"location":"records/#23-escalationrecord","text":"Represents a governed human escalation. Fields: - trigger_trace_id : Hash - escalation_rule_id : Hash - assigned_humans : List - resolution_decision_event_id : Hash - resolution_trace_id : Hash - signatures : List Properties: - Records full escalation lifecycle. - First-class authoritative process.","title":"2.3 EscalationRecord"},{"location":"records/#24-operationalrecord","text":"Represents operational system or human events. Fields: - operation_type : Enum - operation_actor : Enum(HUMAN|SYSTEM) - actor_identity_id : Hash - affected_components : List - operation_payload : DeterministicObject - signatures : List","title":"2.4 OperationalRecord"},{"location":"records/#3-definitional-record-types","text":"These records define how future behavior works.","title":"3. Definitional Record Types"},{"location":"records/#31-decisionpoint","text":"Defines a place where a decision occurs. Fields: - name : String - description : String - outcomes : List - signatures : List","title":"3.1 DecisionPoint"},{"location":"records/#32-precondition","text":"Defines a boolean predicate. Fields: - name : String - description : String - predicate_expression : BooleanExpression - signatures : List Properties: - Must be deterministic. - No side effects.","title":"3.2 Precondition"},{"location":"records/#33-escalationrule","text":"Defines when human escalation occurs. Fields: - name : String - description : String - trigger_condition : BooleanExpression - escalation_target_role : Role - signatures : List","title":"3.3 EscalationRule"},{"location":"records/#34-intentskeleton","text":"Defines a behavioral template. Fields: - name : String - description : String - stages : List - transitions : List - signatures : List","title":"3.4 IntentSkeleton"},{"location":"records/#35-changeset","text":"Defines a change to system logic. Fields: - change_type : Enum(ADD|UPDATE|DEPRECATE) - target_record_type : Enum - target_record_id : Hash - new_definition : Record - rationale : String - approvals : List - signatures : List","title":"3.5 ChangeSet"},{"location":"records/#4-referential-integrity","text":"All canonical records must reference only existing canonical records. Records with invalid references are rejected.","title":"4. Referential Integrity"},{"location":"records/#5-validation-consensus","text":"A canonical record is valid only if: - Schema is valid. - References are valid. - Required signatures are present. - All replicas reach unanimous consensus.","title":"5. Validation &amp; Consensus"},{"location":"schemas_v1/","text":"Schemas Canonical Record Schemas for architecture_v1 DecisionEvent Fields: - decision_point_id : Hash - intent_context_id : Hash - outcome : Enum - reason_code : Enum - based_on_trace_id : Hash - signatures : List Constraints: - outcome must be allowed by DecisionPoint - no timestamp field - no free-text fields ExecutionTrace Fields: - intent_context_id : Hash - trace_type : Enum - subject_id : Hash - previous_trace_id : Hash | null - resulting_context_id : Hash - signatures : List Constraints: - no cycles - append-only EscalationRecord Fields: - trigger_trace_id : Hash - escalation_rule_id : Hash - assigned_humans : List - resolution_decision_event_id : Hash - resolution_trace_id : Hash - signatures : List DecisionPoint Fields: - name : String - description : String - outcomes : List - signatures : List Precondition Fields: - name : String - description : String - predicate_expression : BooleanExpression - signatures : List EscalationRule Fields: - name : String - description : String - trigger_condition : BooleanExpression - escalation_target_role : Role - signatures : List IntentSkeleton Fields: - name : String - description : String - stages : List - transitions : List - signatures : List ChangeSet Fields: - change_type : Enum(ADD|UPDATE|DEPRECATE) - target_record_type : Enum - target_record_id : Hash - new_definition : Record - rationale : String - approvals : List - signatures : List","title":"Schemas"},{"location":"schemas_v1/#schemas","text":"Canonical Record Schemas for architecture_v1","title":"Schemas"},{"location":"schemas_v1/#decisionevent","text":"Fields: - decision_point_id : Hash - intent_context_id : Hash - outcome : Enum - reason_code : Enum - based_on_trace_id : Hash - signatures : List Constraints: - outcome must be allowed by DecisionPoint - no timestamp field - no free-text fields","title":"DecisionEvent"},{"location":"schemas_v1/#executiontrace","text":"Fields: - intent_context_id : Hash - trace_type : Enum - subject_id : Hash - previous_trace_id : Hash | null - resulting_context_id : Hash - signatures : List Constraints: - no cycles - append-only","title":"ExecutionTrace"},{"location":"schemas_v1/#escalationrecord","text":"Fields: - trigger_trace_id : Hash - escalation_rule_id : Hash - assigned_humans : List - resolution_decision_event_id : Hash - resolution_trace_id : Hash - signatures : List","title":"EscalationRecord"},{"location":"schemas_v1/#decisionpoint","text":"Fields: - name : String - description : String - outcomes : List - signatures : List","title":"DecisionPoint"},{"location":"schemas_v1/#precondition","text":"Fields: - name : String - description : String - predicate_expression : BooleanExpression - signatures : List","title":"Precondition"},{"location":"schemas_v1/#escalationrule","text":"Fields: - name : String - description : String - trigger_condition : BooleanExpression - escalation_target_role : Role - signatures : List","title":"EscalationRule"},{"location":"schemas_v1/#intentskeleton","text":"Fields: - name : String - description : String - stages : List - transitions : List - signatures : List","title":"IntentSkeleton"},{"location":"schemas_v1/#changeset","text":"Fields: - change_type : Enum(ADD|UPDATE|DEPRECATE) - target_record_type : Enum - target_record_id : Hash - new_definition : Record - rationale : String - approvals : List - signatures : List","title":"ChangeSet"},{"location":"version_history/","text":"Version History Canonical Record Schemas for architecture_v1 DecisionEvent Fields: - decision_point_id : Hash - intent_context_id : Hash - outcome : Enum - reason_code : Enum - based_on_trace_id : Hash - signatures : List Constraints: - outcome must be allowed by DecisionPoint - no timestamp field - no free-text fields ExecutionTrace Fields: - intent_context_id : Hash - trace_type : Enum - subject_id : Hash - previous_trace_id : Hash | null - resulting_context_id : Hash - signatures : List Constraints: - no cycles - append-only EscalationRecord Fields: - trigger_trace_id : Hash - escalation_rule_id : Hash - assigned_humans : List - resolution_decision_event_id : Hash - resolution_trace_id : Hash - signatures : List DecisionPoint Fields: - name : String - description : String - outcomes : List - signatures : List Precondition Fields: - name : String - description : String - predicate_expression : BooleanExpression - signatures : List EscalationRule Fields: - name : String - description : String - trigger_condition : BooleanExpression - escalation_target_role : Role - signatures : List IntentSkeleton Fields: - name : String - description : String - stages : List - transitions : List - signatures : List ChangeSet Fields: - change_type : Enum(ADD|UPDATE|DEPRECATE) - target_record_type : Enum - target_record_id : Hash - new_definition : Record - rationale : String - approvals : List - signatures : List","title":"Version History"},{"location":"version_history/#version-history","text":"Canonical Record Schemas for architecture_v1","title":"Version History"},{"location":"version_history/#decisionevent","text":"Fields: - decision_point_id : Hash - intent_context_id : Hash - outcome : Enum - reason_code : Enum - based_on_trace_id : Hash - signatures : List Constraints: - outcome must be allowed by DecisionPoint - no timestamp field - no free-text fields","title":"DecisionEvent"},{"location":"version_history/#executiontrace","text":"Fields: - intent_context_id : Hash - trace_type : Enum - subject_id : Hash - previous_trace_id : Hash | null - resulting_context_id : Hash - signatures : List Constraints: - no cycles - append-only","title":"ExecutionTrace"},{"location":"version_history/#escalationrecord","text":"Fields: - trigger_trace_id : Hash - escalation_rule_id : Hash - assigned_humans : List - resolution_decision_event_id : Hash - resolution_trace_id : Hash - signatures : List","title":"EscalationRecord"},{"location":"version_history/#decisionpoint","text":"Fields: - name : String - description : String - outcomes : List - signatures : List","title":"DecisionPoint"},{"location":"version_history/#precondition","text":"Fields: - name : String - description : String - predicate_expression : BooleanExpression - signatures : List","title":"Precondition"},{"location":"version_history/#escalationrule","text":"Fields: - name : String - description : String - trigger_condition : BooleanExpression - escalation_target_role : Role - signatures : List","title":"EscalationRule"},{"location":"version_history/#intentskeleton","text":"Fields: - name : String - description : String - stages : List - transitions : List - signatures : List","title":"IntentSkeleton"},{"location":"version_history/#changeset","text":"Fields: - change_type : Enum(ADD|UPDATE|DEPRECATE) - target_record_type : Enum - target_record_id : Hash - new_definition : Record - rationale : String - approvals : List - signatures : List","title":"ChangeSet"},{"location":"whitepapers/","text":"Whitepapers This page hosts the official research publications of the Deterministic Governance Systems project. These papers are not marketing material . They are formal position papers that establish how digital authority must be constructed and governed in AI-mediated systems. Designing Deterministic Governance for the AI Era A foundational whitepaper establishing why explicit intent, explicit authority, and proof-before-action are mandatory for any system that exercises real-world power. It presents a unified theory of deterministic digital governance spanning law, technology, institutions, security, and society in the age of AI. Download PDF The Decision Layer A focused architectural paper defining the Decision Layer as a deterministic governance substrate that separates intelligence from authority in AI-powered systems. It explains how decisions become explicit, attributable, replayable, and contestable without constraining AI capability. Download PDF Reading guidance These papers are intended to be read as complete arguments. No role-based summaries, selective interpretation, or audience-specific framing is prescribed. They are written for designers, regulators, operators, researchers, and citizens seeking clarity on how authority must function in systems shaped by AI.","title":"Whitepapers"},{"location":"whitepapers/#whitepapers","text":"This page hosts the official research publications of the Deterministic Governance Systems project. These papers are not marketing material . They are formal position papers that establish how digital authority must be constructed and governed in AI-mediated systems.","title":"Whitepapers"},{"location":"whitepapers/#designing-deterministic-governance-for-the-ai-era","text":"A foundational whitepaper establishing why explicit intent, explicit authority, and proof-before-action are mandatory for any system that exercises real-world power. It presents a unified theory of deterministic digital governance spanning law, technology, institutions, security, and society in the age of AI. Download PDF","title":"Designing Deterministic Governance for the AI Era"},{"location":"whitepapers/#the-decision-layer","text":"A focused architectural paper defining the Decision Layer as a deterministic governance substrate that separates intelligence from authority in AI-powered systems. It explains how decisions become explicit, attributable, replayable, and contestable without constraining AI capability. Download PDF","title":"The Decision Layer"},{"location":"whitepapers/#reading-guidance","text":"These papers are intended to be read as complete arguments. No role-based summaries, selective interpretation, or audience-specific framing is prescribed. They are written for designers, regulators, operators, researchers, and citizens seeking clarity on how authority must function in systems shaped by AI.","title":"Reading guidance"}]}